name: Process Uploaded Media

on:
  workflow_dispatch: # Allows manual triggering

  push:
    branches:
      - '*' # Run on pushes to any branch
    paths:
      - 'uploads/**'
      - '.github/workflows/process_media.yml'
      - '.github/scripts/**' # Monitor all scripts

  pull_request:
    types: [opened, synchronize]
    branches:
      - 'main' # Or your default branch
    paths:
      - 'uploads/**'
      - '.github/workflows/process_media.yml'
      - '.github/scripts/**'

permissions:
  contents: write
  id-token: write
  
jobs:
  process_media:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-generativeai
          sudo apt-get update && sudo apt-get install -y ffmpeg imagemagick libimage-exiftool-perl

      - name: Create output directories
        run: |
          mkdir -p processed_media/images
          mkdir -p processed_media/videos
          mkdir -p processed_media/descriptions # For .md files
          mkdir -p processed_media/html # For .html files
          # mkdir -p processed_flags # No longer needed

      - name: Process new media files
        id: process_files
        run: |
          echo "::group::Processing Files"
          # Ensure the uploads directory exists
          if [ ! -d "uploads" ]; then
            echo "Uploads directory not found. Skipping."
            echo "::endgroup::"
            exit 0
          fi

          # Make Python scripts executable (idempotent)
          # The process_file.py script itself calls get_gemini_description.py, so only process_file.py needs to be executable by the workflow directly.
          # The get_gemini_description.py will be called by python interpreter via process_file.py
          chmod +x .github/scripts/process_file.py

          # Find all files in the uploads directory
          # We use a loop to process one file at a time to better manage logs and potential errors.
          find uploads -type f | while read file; do
            echo "--------------------------------------------------"
            echo "Processing file in workflow: $file"
            file_hash=$(md5sum "$file" | awk '{ print $1 }')
            echo "File hash: $file_hash"

            # Determine the target ref for raw URLs.
            # Default to 'refs/heads/main' as per previous requirement.
            # This could be made more dynamic, e.g., use GITHUB_REF_NAME if it's 'main', otherwise GITHUB_SHA.
            # For now, keeping it simple as 'refs/heads/main'.
            target_ref_for_raw_url="refs/heads/main"
            echo "Target ref for raw URLs: $target_ref_for_raw_url"
            echo "GitHub Repository: ${{ github.repository }}"
            echo "Calling Python script: .github/scripts/process_file.py"

            python .github/scripts/process_file.py \
              --input-file "$file" \
              --file-hash "$file_hash" \
              --gemini-api-key "${{ secrets.GEMINI_API_KEY }}" \
              --github-repository "${{ github.repository }}" \
              --github-ref-for-raw-url "$target_ref_for_raw_url"

            exit_code=$?
            if [ $exit_code -ne 0 ]; then
              echo "::error file=$file,title=Processing Error::Python script process_file.py exited with code $exit_code for file $file."
              # Optionally, decide if the whole workflow should fail:
              # exit 1
            else
              echo "Python script process_file.py completed successfully for $file."
            fi
            echo "Finished workflow processing for $file."
            echo "--------------------------------------------------"
          done
          echo "::endgroup::"

      - name: Commit processed files
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'

          echo "Staging processed files for commit..."
          # Stage all new, modified, and deleted files within processed_media/ and for index.json
          git add -A processed_media/ index.json || echo "Warning: git add command encountered an issue or no files to add from processed_media or index.json."

          echo "Current git status before commit:"
          git status -s

          # Only commit if there are changes staged
          if ! git diff --staged --quiet; then
            echo "Files staged for commit:"
            git diff --staged --name-only

            echo "Files staged for commit:"
            git diff --staged --name-only

            echo "Committing changes..."
            git commit -m "Process media files, add descriptions, and preserve metadata"

            echo "Git status after commit (before fetch/rebase):"
            git status -s

            CURRENT_BRANCH_NAME="${{ github.head_ref || github.ref_name }}"

            echo "Fetching origin..."
            git fetch origin

            echo "Rebasing local commit onto origin/$CURRENT_BRANCH_NAME..."
            # If rebase fails (e.g. conflicts), the workflow will stop here.
            git rebase "origin/$CURRENT_BRANCH_NAME"

            echo "Pushing changes to origin HEAD:$CURRENT_BRANCH_NAME"
            git push origin HEAD:"$CURRENT_BRANCH_NAME"
          else
            echo "No changes to commit."
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
